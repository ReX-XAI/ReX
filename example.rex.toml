[rex]
# masking value for mutations, can be either an integer, float or
# one of the following built-in occlusions 'spectral', 'min', 'mean'
# mask_value = 0

# random seed, only set for reproducibility
# seed = 42

# whether to use gpu or not, defaults to true
# gpu = true

# batch size for the model
# batch_size = 64

[rex.onnx]
# means for min-max normalization
# means = [0.485, 0.456, 0.406]

# stds = [0.229, 0.224, 0.225]

# binary model confidence threshold. Anything >= threshold will be classified as 1, otherwise 0
# binary_threshold = 0.5

# norm = 255.0

# intra_op_num_threads = 8

# inter_op_num_threads = 8

# ort_logger = 3

[rex.visual]
# whether to show progress bar in the terminal, defaults to true
# progress_bar = false

# resize the explanation to the size of the original image. This uses cubic interpolation and will not be as visually accurate as not resizing, defaults to false
# resize = true

# include classification and confidence information in title of plot, defaults to true
# info = false

# produce unvarnished image with actual masking value, defaults to false
# raw = false

# pretty printing colour for explanations, defaults to 200
# colour = 100

# matplotlib colourscheme for responsibility map plotting, defaults to 'magma'
# heatmap_colours = 'coolwarm'

# alpha blend for main image, defaults to 0.2 (PIL Image.blend parameter)
# alpha = 0.2

# overlay a 10*10 grid on an explanation, defaults to false
# grid = false

# mark quickshift segmentation on image
# mark_segments = false

# multi_style explanations, either <composite> or <separate>
# multi_style = "composite"

[causal]
# maximum depth of tree, defaults to 10, note that search can actually go beyond this number on occasion, as the
# check only occurs at the end of an iteration
# tree_depth = 30

# limit on number of combinations to consider <per iteration>, defaults to none.
# It is **not** the total work done by ReX over all iterations. Leaving the search limit at none
# can potentially be very expensive.
# search_limit = 1000

# number of times to run the algorithm, defaults to 20
# iters = 30

# minimum child size, in pixels
# min_box_size = 10

# remove passing mutants which have a confidence less thatn <confidence_filter>. Defaults to 0.0 (meaning all mutants are considered)
# confidence_filter = 0.5

# whether to weight responsibility by prediction confidence, default to false
# weighted = false

# queue_style = "intersection" | "area" | "all" | "dc", defaults to "area"
# queue_style = "area"

# maximum number of things to hold in search queue, either an integer or 'all'
# queue_len = 1

# concentrate: weight responsibility by size and depth of passing partition. Defaults to false
# concentrate = true

[causal.distribution]
# distribution for splitting the box, defaults to uniform. Possible choices are 'uniform' | 'binom' | 'betabinom' | 'adaptive'
# distribution = 'uniform'

# blend = 0.5

# supplimental arguments for distribution creation, these are ignored if <distribution> does not take any parameters
# dist_args = [1.1, 1.1]

[explanation]
# iterate through pixel ranking in chunks, defaults to causal.min_box_size
# chunk_size = 10

# causal explanations are minimal by definition, but very small explanations might have very low confidence. ReX will keep 
# looking for an explanation of confidence greater than or equal to the model confidence on <entire image * minimum_confidence_threshold>. 
# This is especially useful to reduce errors due to floating point imprecision when batching calls to the model.
# Defaults to 0.0, with maximum value 1.0. 
# minimum_confidence_threshold = 0.1

[explanation.spatial]
# initial search radius
# initial_radius = 25

# increment to change radius
# radius_eta = 0.2

# number of times to expand before quitting, defaults to 10
# no_expansions = 4

[explanation.multi]
# multi method (just spotlight so far)
# method = 'spotlight'

# no of spotlights to launch
# spotlights = 10

# default size of spotlight
# spotlight_size = 24

# decrease spotlight by this amount
# spotlight_eta = 0.2

# maximum number of random steps that a spotlight can make before quitting
# max_spotlight_budget = 40

# objective function for spotlight search. Possible options 'mean' | 'max' | "none"
# objective_function = 'none'

# permitted_overlap = 0.5

[explanation.evaluation]

# normalise insertion/deletion curves by confidence of original data
# normalise_curves = false

# insertion/deletion curve step size
# insertion_step = 100


